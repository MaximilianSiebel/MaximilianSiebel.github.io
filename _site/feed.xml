<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2024-10-11T12:43:34+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Maximilian Siebel</title><subtitle>Maximilian Siebel is a Phd student at Heidelberg University.
</subtitle><author><name>&lt;Maximilian&gt; &lt;Siebel&gt;</name><email>&lt;siebel@math.uni-heidelberg.de&gt;</email></author><entry><title type="html">New Article on ArXiv!</title><link href="http://localhost:4000/news/2024-09-05-MAP/" rel="alternate" type="text/html" title="New Article on ArXiv!" /><published>2024-09-05T00:00:00+02:00</published><updated>2024-10-10T15:29:36+02:00</updated><id>http://localhost:4000/news/MAP</id><content type="html" xml:base="http://localhost:4000/news/2024-09-05-MAP/"><![CDATA[<p><strong>Title:</strong> Convergence Rates for the Maximum A Posteriori Estimator in PDE-Regression Models with Random Design</p>

<p><strong>Authors:</strong>  Maximilian Siebel</p>

<p><strong>Abstract:</strong> We consider the statistical inverse problem of recovering a parameter θ∈Hα from data arising from the Gaussian regression problem
	<span class="katex-error" title="ParseError: KaTeX parse error: {equation} can be used only in display mode." style="color:#cc0000">\begin{equation}
			Y = \mathscr{G}(\theta)(Z)+\varepsilon
		\end{equation}</span>
with nonlinear forward map <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">G</mi><mo>:</mo><msup><mi mathvariant="double-struck">L</mi><mn>2</mn></msup><mo>→</mo><msup><mi mathvariant="double-struck">L</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\mathscr{G}:\mathbb{L}^2\to\mathbb{L}^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7em;"></span><span class="mord mathscr" style="margin-right:0.17322em;">G</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathbb">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathbb">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>, random design points <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> and Gaussian noise <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ε</mi></mrow><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ε</span></span></span></span>. The estimation strategy is based on a least squares approach under <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mo>⋅</mo><msub><mi mathvariant="normal">∥</mi><msup><mi>H</mi><mi>α</mi></msup></msub></mrow><annotation encoding="application/x-tex">\Vert\cdot\Vert_{H^\alpha}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5935em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em;">α</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>-constraints. We establish the existence of a least squares estimator <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>θ</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{\theta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9579em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9579em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> as a maximizer for a given functional under Lipschitz-type assumptions on the forward map <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">G</mi></mrow><annotation encoding="application/x-tex">\mathscr{G}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7em;"></span><span class="mord mathscr" style="margin-right:0.17322em;">G</span></span></span></span>. A general concentration result is shown, which is used to prove consistency and upper bounds for the prediction error. The corresponding rates of convergence reflect not only the smoothness of the parameter of interest but also the ill-posedness of the underlying inverse problem. We apply the general model to the Darcy problem, where the recovery of an unknown coefficient function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> of a PDE is of interest. For this example, we also provide corresponding rates of convergence for the prediction and estimation errors. Additionally, we briefly discuss the applicability of the general model to other problems.</p>

<p><strong>Link:</strong> <a href="https://arxiv.org/abs/2409.03417">https://arxiv.org/abs/2409.03417</a></p>]]></content><author><name>&lt;Maximilian&gt; &lt;Siebel&gt;</name><email>&lt;siebel@math.uni-heidelberg.de&gt;</email></author><category term="news" /><summary type="html"><![CDATA[Title: Convergence Rates for the Maximum A Posteriori Estimator in PDE-Regression Models with Random Design]]></summary></entry><entry><title type="html">New Article on ArXiv!</title><link href="http://localhost:4000/news/2024-07-20-RegODE/" rel="alternate" type="text/html" title="New Article on ArXiv!" /><published>2024-07-20T00:00:00+02:00</published><updated>2024-10-10T15:09:53+02:00</updated><id>http://localhost:4000/news/RegODE</id><content type="html" xml:base="http://localhost:4000/news/2024-07-20-RegODE/"><![CDATA[<p><strong>Title:</strong> Lower Bounds for Nonparametric Estimation of Ordinary Differential Equations</p>

<p><strong>Authors:</strong> Christof Schötz, Maximilian Siebel</p>

<p><strong>Abstract:</strong> We noisily observe solutions of an ordinary differential equation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>u</mi><mo>˙</mo></mover><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\dot{u}=f(u)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6679em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">u</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">˙</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mclose">)</span></span></span></span> at given times, where u lives in a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span>-dimensional state space. The model function f is unknown and belongs to a Hölder-type smoothness class with parameter <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span>. For the nonparametric problem of estimating <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span>, we provide lower bounds on the error in two complementary model specifications: the snake model with few, long observed solutions and the stubble model with many short ones. The lower bounds are minimax optimal in some settings. They depend on various parameters, which in the optimal asymptotic regime leads to the same rate for the squared error in both models: it is characterized by the exponent <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>2</mn><mi>β</mi><mi mathvariant="normal">/</mi><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">(</mo><mi>β</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo><mo>+</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">−2\beta/(2(\beta+1)+d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord">/</span><span class="mopen">(</span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span> for the total number of observations <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span>. To derive these results, we establish a master theorem for lower bounds in general nonparametric regression problems, which makes the proofs more comparable and seems to be a useful tool for future use.</p>

<p><strong>Link:</strong> <a href="https://arxiv.org/abs/2407.14993">https://arxiv.org/abs/2407.14993</a></p>

<p><img src="/assets/img/blog/RegODE/snake_data_paper.pdf" alt="200x200" /></p>]]></content><author><name>&lt;Maximilian&gt; &lt;Siebel&gt;</name><email>&lt;siebel@math.uni-heidelberg.de&gt;</email></author><category term="news" /><summary type="html"><![CDATA[Title: Lower Bounds for Nonparametric Estimation of Ordinary Differential Equations]]></summary></entry><entry><title type="html">18. Doktorand:innentreffen der Stochastik 2023</title><link href="http://localhost:4000/news/2023-08-21-DokTreff/" rel="alternate" type="text/html" title="18. Doktorand:innentreffen der Stochastik 2023" /><published>2023-08-21T00:00:00+02:00</published><updated>2024-10-10T15:26:00+02:00</updated><id>http://localhost:4000/news/DokTreff</id><content type="html" xml:base="http://localhost:4000/news/2023-08-21-DokTreff/"><![CDATA[<p><strong>18. Doktorand:innentreffen der Stochastik 2023</strong></p>

<p>The 18. Doktorand:innentreffen der Stochastik will take place 21.08. - 23.08.23 (Monday-Wednesday) at the University of Heidelberg. This annual meeting is organised by and for doctoral students in the fields of probability theory and statistics and will be held in Heidelberg for the first time this year.
We offer doctoral students a platform to present their research areas and results, gain insights into other interesting research areas in their field, and exchange ideas with others.
The organisers Bianca Neubert, Ricardo Blum, Henning Stein and Maximilian Siebel look forward to meeting you at University of Heidelberg!
Please note that the number of participants is limited and registration is required.</p>

<p><strong>Link:</strong> <a href="https://stat.math.uni-heidelberg.de/dts2023/index.html">https://stat.math.uni-heidelberg.de/dts2023/index.html</a></p>

<p><img src="/assets/img/blog/DokTreff/group_photo.jpg" alt="200x200" /></p>]]></content><author><name>&lt;Maximilian&gt; &lt;Siebel&gt;</name><email>&lt;siebel@math.uni-heidelberg.de&gt;</email></author><category term="news" /><summary type="html"><![CDATA[18. Doktorand:innentreffen der Stochastik 2023]]></summary></entry><entry><title type="html">New Article on ArXiv!</title><link href="http://localhost:4000/news/2023-08-16-MUDUNER/" rel="alternate" type="text/html" title="New Article on ArXiv!" /><published>2023-08-16T00:00:00+02:00</published><updated>2024-10-10T15:26:00+02:00</updated><id>http://localhost:4000/news/MUDUNER</id><content type="html" xml:base="http://localhost:4000/news/2023-08-16-MUDUNER/"><![CDATA[<p><strong>Title:</strong> Multiplicative deconvolution under unknown error distribution</p>

<p><strong>Authors:</strong> Sergio Brenner Miguel, Jan Johannes, Maximilian Siebel</p>

<p><strong>Abstract:</strong> We consider a multiplicative deconvolution problem, in which the density <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> or the survival function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>S</mi><mi>X</mi></msup></mrow><annotation encoding="application/x-tex">S^X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span></span></span></span></span></span></span></span> of a strictly positive random variable <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> is estimated nonparametrically based on an i.i.d. sample from a noisy observation <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi><mo>=</mo><mi>X</mi><mo>⋅</mo><mi>U</mi></mrow><annotation encoding="application/x-tex">Y=X⋅U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span> of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>. The multiplicative measurement error <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span></span></span></span> is supposed to be independent of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>. The objective of this work is to construct a fully data-driven estimation procedure when the error density <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>f</mi><mi>U</mi></msup></mrow><annotation encoding="application/x-tex">f^U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">U</span></span></span></span></span></span></span></span></span></span></span> is unknown. We assume that in addition to the i.i.d. sample from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span>, we have at our disposal an additional i.i.d. sample drawn independently from the error distribution. The proposed estimation procedure combines the estimation of the Mellin transformation of the density <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> and a regularisation of the inverse of the Mellin transform by a spectral cut-off. The derived risk bounds and oracle-type inequalities cover both - the estimation of the density <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span> as well as the survival function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>S</mi><mi>X</mi></msup></mrow><annotation encoding="application/x-tex">S^X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07847em;">X</span></span></span></span></span></span></span></span></span></span></span>. The main issue addressed in this work is the data-driven choice of the cut-off parameter using a model selection approach. We discuss conditions under which the fully data-driven estimator can attain the oracle-risk up to a constant without any previous knowledge of the error distribution. We compute convergences rates under classical smoothness assumptions. We illustrate the estimation strategy by a simulation study with different choices of distributions.</p>

<p><strong>Link:</strong> <a href="https://arxiv.org/abs/2308.08423">https://arxiv.org/abs/2308.08423</a></p>]]></content><author><name>&lt;Maximilian&gt; &lt;Siebel&gt;</name><email>&lt;siebel@math.uni-heidelberg.de&gt;</email></author><category term="news" /><summary type="html"><![CDATA[Title: Multiplicative deconvolution under unknown error distribution]]></summary></entry></feed>